{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "265ef32e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T12:43:23.340928Z",
     "iopub.status.busy": "2023-07-07T12:43:23.340379Z",
     "iopub.status.idle": "2023-07-07T12:45:09.515828Z",
     "shell.execute_reply": "2023-07-07T12:45:09.514559Z"
    },
    "papermill": {
     "duration": 106.186144,
     "end_time": "2023-07-07T12:45:09.518705",
     "exception": false,
     "start_time": "2023-07-07T12:43:23.332561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87adf404",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-07T12:45:09.529279Z",
     "iopub.status.busy": "2023-07-07T12:45:09.528377Z",
     "iopub.status.idle": "2023-07-07T12:45:17.958807Z",
     "shell.execute_reply": "2023-07-07T12:45:17.957734Z"
    },
    "papermill": {
     "duration": 8.4381,
     "end_time": "2023-07-07T12:45:17.961336",
     "exception": false,
     "start_time": "2023-07-07T12:45:09.523236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b41172f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T12:45:17.971711Z",
     "iopub.status.busy": "2023-07-07T12:45:17.971108Z",
     "iopub.status.idle": "2023-07-07T12:45:18.098736Z",
     "shell.execute_reply": "2023-07-07T12:45:18.097757Z"
    },
    "papermill": {
     "duration": 0.13514,
     "end_time": "2023-07-07T12:45:18.101099",
     "exception": false,
     "start_time": "2023-07-07T12:45:17.965959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/hackathon23/new_data_lun.csv')\n",
    "# для тренування на всіх даних видаліть + random split на train_dataframe і val_dataframe (далі комірка)\n",
    "# train_data = train_data[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22270561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T12:45:18.112079Z",
     "iopub.status.busy": "2023-07-07T12:45:18.110575Z",
     "iopub.status.idle": "2023-07-07T12:45:18.132844Z",
     "shell.execute_reply": "2023-07-07T12:45:18.131945Z"
    },
    "papermill": {
     "duration": 0.029745,
     "end_time": "2023-07-07T12:45:18.135098",
     "exception": false,
     "start_time": "2023-07-07T12:45:18.105353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataframe, val_dataframe = train_test_split(train_data, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da93b86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T12:45:18.144790Z",
     "iopub.status.busy": "2023-07-07T12:45:18.144493Z",
     "iopub.status.idle": "2023-07-07T12:45:18.156238Z",
     "shell.execute_reply": "2023-07-07T12:45:18.155369Z"
    },
    "papermill": {
     "duration": 0.019044,
     "end_time": "2023-07-07T12:45:18.158299",
     "exception": false,
     "start_time": "2023-07-07T12:45:18.139255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataframe, batch_size=64, image_size=(224, 224)):\n",
    "        self.dataframe = dataframe\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataframe) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_df = self.dataframe[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        batch_images1 = []\n",
    "        batch_images2 = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for _, row in batch_df.iterrows():\n",
    "            img1_url, img2_url, label = row['image_url1'], row['image_url2'], row['is_same']\n",
    "            image1 = Image.open(os.path.join('/kaggle/input/hackathon23/train-files/images/', img1_url))\n",
    "            image2 = Image.open(os.path.join('/kaggle/input/hackathon23/train-files/images/', img2_url))\n",
    "            if image1.mode == \"L\" or image1.mode == \"RGBA\":\n",
    "                image1 = image1.convert(\"RGB\")\n",
    "            if image2.mode == \"L\" or image2.mode == \"RGBA\":\n",
    "                image2 = image2.convert(\"RGB\")\n",
    "            \n",
    "            image1 = image1.resize((224, 224))  \n",
    "            image2 = image2.resize((224, 224))  \n",
    "                \n",
    "            image1 = tf.convert_to_tensor(image1)\n",
    "            image2 = tf.convert_to_tensor(image2)\n",
    "\n",
    "            batch_images1.append(image1)\n",
    "            batch_images2.append(image2)\n",
    "            batch_labels.append(label)\n",
    "\n",
    "        batch_images1 = np.array(batch_images1) / 255.0  # Normalize images\n",
    "        batch_images2 = np.array(batch_images2) / 255.0  # Normalize images\n",
    "        batch_labels = np.array(batch_labels)\n",
    "        return batch_images1, batch_images2, batch_labels\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.dataframe = self.dataframe.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f2e9535",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T12:45:18.167677Z",
     "iopub.status.busy": "2023-07-07T12:45:18.167406Z",
     "iopub.status.idle": "2023-07-07T12:45:21.039419Z",
     "shell.execute_reply": "2023-07-07T12:45:21.038479Z"
    },
    "papermill": {
     "duration": 2.879621,
     "end_time": "2023-07-07T12:45:21.041926",
     "exception": false,
     "start_time": "2023-07-07T12:45:18.162305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_generator = DataGenerator(train_dataframe, batch_size=32)\n",
    "val_data_generator = DataGenerator(val_dataframe, batch_size=32)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_data_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    "    )\n",
    ")\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: val_data_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b1c1ace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T12:45:21.052678Z",
     "iopub.status.busy": "2023-07-07T12:45:21.051197Z",
     "iopub.status.idle": "2023-07-07T12:45:21.058195Z",
     "shell.execute_reply": "2023-07-07T12:45:21.057331Z"
    },
    "papermill": {
     "duration": 0.014052,
     "end_time": "2023-07-07T12:45:21.060266",
     "exception": false,
     "start_time": "2023-07-07T12:45:21.046214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_batched(x1, x2):\n",
    "    # Compute L2-norm of each vector\n",
    "    x1_norm = tf.linalg.norm(x1, axis=1, keepdims=True)\n",
    "    x2_norm = tf.linalg.norm(x2, axis=1, keepdims=True)\n",
    "\n",
    "    # Compute dot product between vectors\n",
    "    dot_product = tf.reduce_sum(x1 * x2, axis=1, keepdims=True)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_similarity = dot_product / (x1_norm * x2_norm + tf.keras.backend.epsilon())\n",
    "\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10fb7405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T12:45:21.073049Z",
     "iopub.status.busy": "2023-07-07T12:45:21.072131Z",
     "iopub.status.idle": "2023-07-07T12:45:21.084699Z",
     "shell.execute_reply": "2023-07-07T12:45:21.083828Z"
    },
    "papermill": {
     "duration": 0.022762,
     "end_time": "2023-07-07T12:45:21.086990",
     "exception": false,
     "start_time": "2023-07-07T12:45:21.064228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_f1_score(y_true, y_pred):\n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    TP = tf.math.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 1), tf.equal(y_pred, 1)), dtype=tf.float32), axis=0)\n",
    "    FP = tf.math.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(y_pred, 1)), dtype=tf.float32), axis=0)\n",
    "    FN = tf.math.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 1), tf.equal(y_pred, 0)), dtype=tf.float32), axis=0)\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = TP / (TP + FP + tf.keras.backend.epsilon())\n",
    "    recall = TP / (TP + FN + tf.keras.backend.epsilon())\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "586d983c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T12:45:21.097243Z",
     "iopub.status.busy": "2023-07-07T12:45:21.096973Z",
     "iopub.status.idle": "2023-07-07T12:45:24.578348Z",
     "shell.execute_reply": "2023-07-07T12:45:24.577350Z"
    },
    "papermill": {
     "duration": 3.489628,
     "end_time": "2023-07-07T12:45:24.580700",
     "exception": false,
     "start_time": "2023-07-07T12:45:21.091072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Input, Sequential, Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import applications, layers, losses, optimizers, metrics\n",
    "\n",
    "mobile_net = VGG16(\n",
    "    weights=\"imagenet\", input_shape=(224,224, 3), include_top=False\n",
    ")\n",
    "\n",
    "flatten = layers.Flatten()(mobile_net.output)\n",
    "x1 = layers.Dense(512, activation=\"relu\")(flatten)\n",
    "x1 = layers.BatchNormalization()(x1)\n",
    "x2 = layers.Dense(256, activation=\"relu\")(x1)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "output = layers.Dense(256)(x2)\n",
    "\n",
    "embedding = Model(mobile_net.input, output, name=\"Embedding\")\n",
    "\n",
    "trainable = False\n",
    "for layer in mobile_net.layers:\n",
    "    if layer.name == \"block5_conv1\":\n",
    "        trainable = True\n",
    "    layer.trainable = trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f7fcd29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T12:45:24.598537Z",
     "iopub.status.busy": "2023-07-07T12:45:24.597649Z",
     "iopub.status.idle": "2023-07-07T12:45:24.650191Z",
     "shell.execute_reply": "2023-07-07T12:45:24.649387Z"
    },
    "papermill": {
     "duration": 0.096089,
     "end_time": "2023-07-07T12:45:24.684723",
     "exception": false,
     "start_time": "2023-07-07T12:45:24.588634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               12845568  \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,760,448\n",
      "Trainable params: 20,123,648\n",
      "Non-trainable params: 7,636,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53429333",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T12:45:24.710762Z",
     "iopub.status.busy": "2023-07-07T12:45:24.710423Z",
     "iopub.status.idle": "2023-07-07T12:45:24.716860Z",
     "shell.execute_reply": "2023-07-07T12:45:24.715867Z"
    },
    "papermill": {
     "duration": 0.021909,
     "end_time": "2023-07-07T12:45:24.718872",
     "exception": false,
     "start_time": "2023-07-07T12:45:24.696963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "def create_siamese_model(input_shape):\n",
    "    # Define inputs\n",
    "    input_1 = layers.Input(name=\"input_1\", shape=input_shape)\n",
    "    input_2 = layers.Input(name=\"input_2\", shape=input_shape)\n",
    "\n",
    "    # Get embeddings from base models\n",
    "    embedding_1 = embedding(input_1)\n",
    "    embedding_2 = embedding(input_2)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_similarity = cosine_similarity_batched(embedding_1, embedding_2)\n",
    "\n",
    "    # Create siamese model\n",
    "    siamese_model = tf.keras.Model(inputs=[input_1, input_2], outputs=cosine_similarity)\n",
    "    return siamese_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "316d1a77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T12:45:24.744243Z",
     "iopub.status.busy": "2023-07-07T12:45:24.743920Z",
     "iopub.status.idle": "2023-07-07T23:40:15.378486Z",
     "shell.execute_reply": "2023-07-07T23:40:15.376597Z"
    },
    "papermill": {
     "duration": 39290.66675,
     "end_time": "2023-07-07T23:40:15.397552",
     "exception": false,
     "start_time": "2023-07-07T12:45:24.730802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "Train Loss: 0.07818122953176498, Train F1: 0.9778134822845459\n",
      "Val Loss: 0.058450888842344284, Val F1: 0.9772791266441345\n",
      "\n",
      "Epoch 2/10:\n",
      "Train Loss: 0.06491358578205109, Train F1: 0.978593647480011\n",
      "Val Loss: 0.05733633413910866, Val F1: 0.9763917922973633\n",
      "\n",
      "Epoch 3/10:\n",
      "Train Loss: 0.06479302793741226, Train F1: 0.9786688089370728\n",
      "Val Loss: 0.07663700729608536, Val F1: 0.9725774526596069\n",
      "\n",
      "Epoch 4/10:\n",
      "Train Loss: 0.06383698433637619, Train F1: 0.9783222079277039\n",
      "Val Loss: 0.058385759592056274, Val F1: 0.9792412519454956\n",
      "\n",
      "Epoch 5/10:\n",
      "Train Loss: 0.04369734600186348, Train F1: 0.9834318161010742\n",
      "Val Loss: 0.05075804889202118, Val F1: 0.982099711894989\n",
      "\n",
      "Epoch 6/10:\n",
      "Train Loss: 0.040756333619356155, Train F1: 0.9850804805755615\n",
      "Val Loss: 0.05211348831653595, Val F1: 0.9828423261642456\n",
      "\n",
      "Epoch 7/10:\n",
      "Train Loss: 0.030423294752836227, Train F1: 0.9874131679534912\n",
      "Val Loss: 0.04625372216105461, Val F1: 0.9835363030433655\n",
      "\n",
      "Epoch 8/10:\n",
      "Train Loss: 0.02603120729327202, Train F1: 0.9896273612976074\n",
      "Val Loss: 0.04705636203289032, Val F1: 0.9830245971679688\n",
      "\n",
      "Epoch 9/10:\n",
      "Train Loss: 0.018432123586535454, Train F1: 0.993363082408905\n",
      "Val Loss: 0.04539557173848152, Val F1: 0.9829010963439941\n",
      "\n",
      "Epoch 10/10:\n",
      "Train Loss: 0.015417088754475117, Train F1: 0.995216429233551\n",
      "Val Loss: 0.04688547924160957, Val F1: 0.9810935258865356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Custom training method\n",
    "def train_model(model, train_dataset, val_dataset, threshold):\n",
    "    # Define loss function\n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "    # Define metrics\n",
    "    train_loss = tf.keras.metrics.Mean()\n",
    "    train_f1 = tf.keras.metrics.Mean()\n",
    "    \n",
    "    best_metric = np.inf\n",
    "\n",
    "    val_loss = tf.keras.metrics.Mean()\n",
    "    val_f1 = tf.keras.metrics.Mean()\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(x1, x2, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            predictions = model([x1, x2])\n",
    "            labels = tf.expand_dims(labels, axis=1)\n",
    "            loss_value = loss_fn(labels, predictions)\n",
    "\n",
    "        # Backward pass\n",
    "        gradients = tape.gradient(loss_value, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # Compute F1 score\n",
    "        f1_value = custom_f1_score(labels, tf.cast(predictions > threshold, tf.int32))\n",
    "\n",
    "        return loss_value, f1_value\n",
    "\n",
    "    @tf.function\n",
    "    def val_step(x1, x2, labels):\n",
    "        # Forward pass\n",
    "        predictions = model([x1, x2])\n",
    "        labels = tf.expand_dims(labels, axis=1)\n",
    "        loss_value = loss_fn(labels, predictions)\n",
    "\n",
    "        # Compute F1 score\n",
    "        f1_value = custom_f1_score(labels, tf.cast(predictions > threshold, tf.int32))\n",
    "\n",
    "        return loss_value, f1_value\n",
    "\n",
    "    # Training loop\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        # Reset metrics\n",
    "        train_loss.reset_states()\n",
    "        train_f1.reset_states()\n",
    "        val_loss.reset_states()\n",
    "        val_f1.reset_states()\n",
    "\n",
    "        # Training\n",
    "        for x1, x2, labels in train_dataset:\n",
    "            loss_value, f1_value = train_step(x1, x2, labels)\n",
    "            train_loss.update_state(loss_value)\n",
    "            train_f1.update_state(f1_value)\n",
    "\n",
    "        # Validation\n",
    "        for x1, x2, labels in val_dataset:\n",
    "            loss_value, f1_value = val_step(x1, x2, labels)\n",
    "            val_loss.update_state(loss_value)\n",
    "            val_f1.update_state(f1_value)\n",
    "\n",
    "        if val_loss.result() < best_metric:\n",
    "            best_metric = val_loss.result()\n",
    "            model.save('/kaggle/working/best_model.h5')\n",
    "        # Print progress\n",
    "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "        print(f\"Train Loss: {train_loss.result()}, Train F1: {train_f1.result()}\")\n",
    "        print(f\"Val Loss: {val_loss.result()}, Val F1: {val_f1.result()}\")\n",
    "        print()\n",
    "\n",
    "# Example usage\n",
    "input_shape = (224, 224, 3)\n",
    "threshold = 0.75\n",
    "\n",
    "# Create the model\n",
    "model = create_siamese_model(input_shape)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_dataset, val_dataset, threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39426.257866,
   "end_time": "2023-07-07T23:40:19.162919",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-07T12:43:12.905053",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
