{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# # detect and init the TPU\n",
    "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "\n",
    "# # instantiate a distribution strategy\n",
    "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T10:06:13.536356Z",
     "iopub.execute_input": "2023-07-08T10:06:13.536730Z",
     "iopub.status.idle": "2023-07-08T10:06:22.454662Z",
     "shell.execute_reply.started": "2023-07-08T10:06:13.536700Z",
     "shell.execute_reply": "2023-07-08T10:06:22.453690Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from PIL import Image"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T11:14:28.230385Z",
     "iopub.execute_input": "2023-07-08T11:14:28.230747Z",
     "iopub.status.idle": "2023-07-08T11:14:28.235968Z",
     "shell.execute_reply.started": "2023-07-08T11:14:28.230718Z",
     "shell.execute_reply": "2023-07-08T11:14:28.234426Z"
    },
    "trusted": true
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dir_img_1 = '/kaggle/input/traindataset/LUN_DataSet/train_url1'\n",
    "dir_img_2 = '/kaggle/input/traindataset/LUN_DataSet/train_url2'"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T11:15:36.681934Z",
     "iopub.execute_input": "2023-07-08T11:15:36.682306Z",
     "iopub.status.idle": "2023-07-08T11:15:36.686609Z",
     "shell.execute_reply.started": "2023-07-08T11:15:36.682277Z",
     "shell.execute_reply": "2023-07-08T11:15:36.685688Z"
    },
    "trusted": true
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Specify the path to the saved model directory\n",
    "model_path = '/kaggle/input/triplet-cosine-dist/best_model'\n",
    "# with tpu_strategy.scope():\n",
    "# Load the saved model\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "feat_vect_mob_net = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v3_large_075_224/feature_vector/5\", trainable=False)\n",
    "feat_vect_mob_net.set_weights(loaded_model.layers[0].get_weights())"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-07-08T11:20:43.775395Z",
     "iopub.execute_input": "2023-07-08T11:20:43.776331Z",
     "iopub.status.idle": "2023-07-08T11:20:50.296467Z",
     "shell.execute_reply.started": "2023-07-08T11:20:43.776294Z",
     "shell.execute_reply": "2023-07-08T11:20:50.295468Z"
    },
    "trusted": true
   },
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def cosine_similarity_batched(x1, x2):\n",
    "    # Compute L2-norm of each vector\n",
    "    x1_norm = tf.linalg.norm(x1, axis=1, keepdims=True)\n",
    "    x2_norm = tf.linalg.norm(x2, axis=1, keepdims=True)\n",
    "\n",
    "    # Compute dot product between vectors\n",
    "    dot_product = tf.reduce_sum(x1 * x2, axis=1, keepdims=True)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_similarity = dot_product / (x1_norm * x2_norm)\n",
    "\n",
    "    return cosine_similarity"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T10:06:33.822474Z",
     "iopub.execute_input": "2023-07-08T10:06:33.823225Z",
     "iopub.status.idle": "2023-07-08T10:06:33.830691Z",
     "shell.execute_reply.started": "2023-07-08T10:06:33.823187Z",
     "shell.execute_reply": "2023-07-08T10:06:33.829575Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def custom_f1_score(y_true, y_pred):\n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    TP = tf.math.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 1), tf.equal(y_pred, 1)), dtype=tf.float32), axis=0)\n",
    "    FP = tf.math.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 0), tf.equal(y_pred, 1)), dtype=tf.float32), axis=0)\n",
    "    FN = tf.math.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, 1), tf.equal(y_pred, 0)), dtype=tf.float32), axis=0)\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T10:06:33.834049Z",
     "iopub.execute_input": "2023-07-08T10:06:33.834400Z",
     "iopub.status.idle": "2023-07-08T10:06:33.843883Z",
     "shell.execute_reply.started": "2023-07-08T10:06:33.834365Z",
     "shell.execute_reply": "2023-07-08T10:06:33.842883Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "TRAINING (select threshold)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_data = pd.read_csv('/kaggle/input/new-data-lun-csv/new_data_lun.csv')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T10:06:33.845443Z",
     "iopub.execute_input": "2023-07-08T10:06:33.845801Z",
     "iopub.status.idle": "2023-07-08T10:06:34.000517Z",
     "shell.execute_reply.started": "2023-07-08T10:06:33.845769Z",
     "shell.execute_reply": "2023-07-08T10:06:33.999390Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataframe, batch_size=32, image_size=(224, 224)):\n",
    "        self.dataframe = dataframe\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataframe) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_df = self.dataframe[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        batch_images1 = []\n",
    "        batch_images2 = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for _, row in batch_df.iterrows():\n",
    "            img1_url, img2_url, label = row['image_url1'], row['image_url2'], row['is_same']\n",
    "            image1 = Image.open(os.path.join(dir_img_1, img1_url))\n",
    "            image2 = Image.open(os.path.join(dir_img_2, img2_url))\n",
    "            if image1.mode == \"L\" or image1.mode == \"RGBA\":\n",
    "                image1 = image1.convert(\"RGB\")\n",
    "            if image2.mode == \"L\" or image2.mode == \"RGBA\":\n",
    "                image2 = image2.convert(\"RGB\")\n",
    "            \n",
    "            image1 = image1.resize((224, 224))  \n",
    "            image2 = image2.resize((224, 224))  \n",
    "                \n",
    "            image1 = tf.convert_to_tensor(image1)\n",
    "            image2 = tf.convert_to_tensor(image2)\n",
    "\n",
    "            batch_images1.append(image1)\n",
    "            batch_images2.append(image2)\n",
    "            batch_labels.append(label)\n",
    "\n",
    "        batch_images1 = np.array(batch_images1) / 255.0  # Normalize images\n",
    "        batch_images2 = np.array(batch_images2) / 255.0  # Normalize images\n",
    "        batch_labels = np.array(batch_labels)\n",
    "        return (batch_images1, batch_images2, batch_labels)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.dataframe = self.dataframe.sample(frac=1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T11:06:13.831703Z",
     "iopub.execute_input": "2023-07-08T11:06:13.832101Z",
     "iopub.status.idle": "2023-07-08T11:06:13.848134Z",
     "shell.execute_reply.started": "2023-07-08T11:06:13.832073Z",
     "shell.execute_reply": "2023-07-08T11:06:13.847009Z"
    },
    "trusted": true
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "split_index = int(len(train_data) * 0.8)\n",
    "train_dataframe = train_data[:split_index]\n",
    "val_dataframe = train_data[split_index:]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T10:06:34.020001Z",
     "iopub.execute_input": "2023-07-08T10:06:34.020720Z",
     "iopub.status.idle": "2023-07-08T10:06:34.029955Z",
     "shell.execute_reply.started": "2023-07-08T10:06:34.020681Z",
     "shell.execute_reply": "2023-07-08T10:06:34.028961Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_data_generator = DataGenerator(train_dataframe, batch_size=32)\n",
    "val_data_generator = DataGenerator(val_dataframe, batch_size=32)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_data_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    "    )\n",
    ")\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: val_data_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T11:06:23.428095Z",
     "iopub.execute_input": "2023-07-08T11:06:23.429022Z",
     "iopub.status.idle": "2023-07-08T11:06:23.505285Z",
     "shell.execute_reply.started": "2023-07-08T11:06:23.428990Z",
     "shell.execute_reply": "2023-07-08T11:06:23.503607Z"
    },
    "trusted": true
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class MyCustomModel(tf.keras.Model):\n",
    "    def __init__(self, threshold):\n",
    "        super(MyCustomModel, self).__init__()\n",
    "        self.threshold = threshold\n",
    "        self.base_model = feat_vect_mob_net\n",
    "\n",
    "    def call(self, inputs):\n",
    "        image1, image2 = inputs\n",
    "        # Get embeddings from base models\n",
    "        embedding_1 = self.base_model(image1)\n",
    "        embedding_2 = self.base_model(image2)\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        cosine_similarity = cosine_similarity_batched(embedding_1, embedding_2)\n",
    "        output = tf.cast(cosine_similarity > self.threshold, tf.int32)\n",
    "        return output"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T11:22:15.984743Z",
     "iopub.execute_input": "2023-07-08T11:22:15.985197Z",
     "iopub.status.idle": "2023-07-08T11:22:15.998700Z",
     "shell.execute_reply.started": "2023-07-08T11:22:15.985159Z",
     "shell.execute_reply": "2023-07-08T11:22:15.997687Z"
    },
    "trusted": true
   },
   "execution_count": 57,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T10:55:49.737949Z",
     "iopub.execute_input": "2023-07-08T10:55:49.738314Z",
     "iopub.status.idle": "2023-07-08T10:55:49.746606Z",
     "shell.execute_reply.started": "2023-07-08T10:55:49.738284Z",
     "shell.execute_reply": "2023-07-08T10:55:49.745265Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": "The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf /logs/"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T10:56:26.387068Z",
     "iopub.execute_input": "2023-07-08T10:56:26.387419Z",
     "iopub.status.idle": "2023-07-08T10:56:27.422319Z",
     "shell.execute_reply.started": "2023-07-08T10:56:26.387388Z",
     "shell.execute_reply": "2023-07-08T10:56:27.420753Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorboard.plugins.hparams import api as hp"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T10:56:30.165041Z",
     "iopub.execute_input": "2023-07-08T10:56:30.165498Z",
     "iopub.status.idle": "2023-07-08T10:56:30.203480Z",
     "shell.execute_reply.started": "2023-07-08T10:56:30.165453Z",
     "shell.execute_reply": "2023-07-08T10:56:30.202625Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "HP_THRESHOLD = hp.HParam('threshold', hp.RealInterval(0.7, 0.9))\n",
    "\n",
    "METRIC_ACCURACY = 'f1'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "    hparams=[HP_THRESHOLD],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='F1')],\n",
    "  )"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T11:08:23.332482Z",
     "iopub.execute_input": "2023-07-08T11:08:23.332879Z",
     "iopub.status.idle": "2023-07-08T11:08:23.340793Z",
     "shell.execute_reply.started": "2023-07-08T11:08:23.332849Z",
     "shell.execute_reply": "2023-07-08T11:08:23.339781Z"
    },
    "trusted": true
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def test_model(hparams):\n",
    "    model = MyCustomModel(hparams[HP_THRESHOLD])\n",
    "    model.compile(optimizer='sgd',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['f1'])\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for inputs1, inputs2, labels in train_dataset:\n",
    "        outputs = model([inputs1, inputs2])\n",
    "        outputs = tf.squeeze(outputs)\n",
    "        outputs = outputs.numpy()\n",
    "        outputs = outputs.tolist()\n",
    "        predictions += outputs\n",
    "        labels = tf.squeeze(labels)\n",
    "        labels = labels.numpy()\n",
    "        labels = labels.tolist()\n",
    "        labels += labels\n",
    "    return f1_score(labels, predictions, average='weighted')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T11:26:06.085653Z",
     "iopub.execute_input": "2023-07-08T11:26:06.086038Z",
     "iopub.status.idle": "2023-07-08T11:26:06.094934Z",
     "shell.execute_reply.started": "2023-07-08T11:26:06.086009Z",
     "shell.execute_reply": "2023-07-08T11:26:06.093860Z"
    },
    "trusted": true
   },
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  \n",
    "        accuracy = test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T11:21:26.951565Z",
     "iopub.execute_input": "2023-07-08T11:21:26.951987Z",
     "iopub.status.idle": "2023-07-08T11:21:26.960362Z",
     "shell.execute_reply.started": "2023-07-08T11:21:26.951954Z",
     "shell.execute_reply": "2023-07-08T11:21:26.959216Z"
    },
    "trusted": true
   },
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "session_num = 0\n",
    "for threshold in (HP_THRESHOLD.domain.min_value, HP_THRESHOLD.domain.max_value):  \n",
    "    hparams = {\n",
    "              HP_THRESHOLD: threshold,\n",
    "          }\n",
    "    run_name = \"run-%d\" % session_num\n",
    "    print('--- Starting trial: %s' % run_name)\n",
    "    print({h.name: hparams[h] for h in hparams})\n",
    "    run('logs/hparam_tuning/' + run_name, hparams)\n",
    "    session_num += 1"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T11:26:09.437998Z",
     "iopub.execute_input": "2023-07-08T11:26:09.438363Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "--- Starting trial: run-0\n{'threshold': 0.7}\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "TEST"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "test_data = pd.read_csv('/kaggle/input/download-test-data-lun/test_data_lun/new_test_data_lun.csv')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T10:06:35.166278Z",
     "iopub.status.idle": "2023-07-08T10:06:35.167407Z",
     "shell.execute_reply.started": "2023-07-08T10:06:35.167143Z",
     "shell.execute_reply": "2023-07-08T10:06:35.167168Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dir_test_1 = '/kaggle/input/download-test-data-lun/test_data_lun/image_url1'\n",
    "dir_test_2 = '/kaggle/input/download-test-data-lun/test_data_lun/image_url2'"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T10:06:35.169023Z",
     "iopub.status.idle": "2023-07-08T10:06:35.169798Z",
     "shell.execute_reply.started": "2023-07-08T10:06:35.169540Z",
     "shell.execute_reply": "2023-07-08T10:06:35.169580Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_submission = pd.read_csv('/kaggle/input/copy-of-csc-hackathon-2023-lunua-task-2/test-data.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/download-test-data-lun/test_data_lun/new_test_data_lun.csv')\n",
    "test_data[\"ID\"] = list(test_submission[\"ID\"].values)\n",
    "test_data.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T10:06:35.171207Z",
     "iopub.status.idle": "2023-07-08T10:06:35.172000Z",
     "shell.execute_reply.started": "2023-07-08T10:06:35.171746Z",
     "shell.execute_reply": "2023-07-08T10:06:35.171769Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "class TestDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataframe, batch_size=32, image_size=(224, 224)):\n",
    "        self.dataframe = dataframe\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataframe) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_df = self.dataframe[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        batch_images1 = []\n",
    "        batch_images2 = []\n",
    "\n",
    "        for _, row in batch_df.iterrows():\n",
    "            img1_url, img2_url = row['image_url1'], row['image_url2']\n",
    "            if img1_url == \"empty\" or img2_url == \"empty\":\n",
    "                image1 = tf.zeros((224, 224, 3))\n",
    "                image2 = tf.zeros((224, 224, 3))\n",
    "            else:\n",
    "                image1 = Image.open(os.path.join(dir_test_1, img1_url))\n",
    "                image2 = Image.open(os.path.join(dir_test_2, img2_url))\n",
    "                if image1.mode == \"L\" or image1.mode == \"RGBA\":\n",
    "                    image1 = image1.convert(\"RGB\")\n",
    "                if image2.mode == \"L\" or image2.mode == \"RGBA\":\n",
    "                    image2 = image2.convert(\"RGB\")\n",
    "\n",
    "                image1 = image1.resize((224, 224))  \n",
    "                image2 = image2.resize((224, 224))  \n",
    "\n",
    "                image1 = tf.convert_to_tensor(image1)\n",
    "                image2 = tf.convert_to_tensor(image2)\n",
    "\n",
    "            batch_images1.append(image1)\n",
    "            batch_images2.append(image2)\n",
    "\n",
    "        batch_images1 = np.array(batch_images1) / 255.0  # Normalize images\n",
    "        batch_images2 = np.array(batch_images2) / 255.0  # Normalize images\n",
    "        return batch_images1, batch_images2"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T10:06:35.173407Z",
     "iopub.status.idle": "2023-07-08T10:06:35.174210Z",
     "shell.execute_reply.started": "2023-07-08T10:06:35.173947Z",
     "shell.execute_reply": "2023-07-08T10:06:35.173970Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from PIL import Image"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T10:06:35.175616Z",
     "iopub.status.idle": "2023-07-08T10:06:35.176388Z",
     "shell.execute_reply.started": "2023-07-08T10:06:35.176150Z",
     "shell.execute_reply": "2023-07-08T10:06:35.176173Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "last_index = 22000\n",
    "prev_idx = 0\n",
    "next_idx = 0\n",
    "predictions = []\n",
    "    \n",
    "for i in range(0, len(test_data), 1000):\n",
    "    print(i)\n",
    "    if i != 0:\n",
    "        next_idx = i\n",
    "        test_df = test_data[prev_idx: next_idx]\n",
    "        test_data_generator = TestDataGenerator(test_df, batch_size=32)\n",
    "\n",
    "        test_dataset = tf.data.Dataset.from_generator(\n",
    "            lambda: test_data_generator,\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "                 tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    "            )\n",
    "        )\n",
    "        prev_idx = i\n",
    "        for inputs1, inputs2 in test_data_generator:\n",
    "            outputs = model([inputs1, inputs1, best_threshold])\n",
    "            outputs = tf.squeeze(outputs)\n",
    "            outputs = outputs.numpy()\n",
    "            outputs = outputs.tolist()\n",
    "            print(outputs)\n",
    "            predictions += outputs"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T10:06:35.177759Z",
     "iopub.status.idle": "2023-07-08T10:06:35.178533Z",
     "shell.execute_reply.started": "2023-07-08T10:06:35.178293Z",
     "shell.execute_reply": "2023-07-08T10:06:35.178316Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_df = test_data[22000:]\n",
    "test_data_generator = TestDataGenerator(test_df, batch_size=32)\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "            lambda: test_data_generator,\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "                 tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    "            )\n",
    "        )\n",
    "prev_idx = i\n",
    "for inputs1, inputs2 in test_data_generator:\n",
    "    outputs = model([inputs1, inputs1, best_threshold])\n",
    "    outputs = tf.squeeze(outputs)\n",
    "    outputs = outputs.numpy()\n",
    "    outputs = outputs.tolist()\n",
    "    predictions += outputs"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T10:06:35.179938Z",
     "iopub.status.idle": "2023-07-08T10:06:35.180744Z",
     "shell.execute_reply.started": "2023-07-08T10:06:35.180459Z",
     "shell.execute_reply": "2023-07-08T10:06:35.180482Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ids = list(test_data[\"ID\"].values)\n",
    "submission = pd.DataFrame()\n",
    "submission[\"ID\"] = ids\n",
    "submission[\"is_same\"] = predictions"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T10:06:35.182176Z",
     "iopub.status.idle": "2023-07-08T10:06:35.182952Z",
     "shell.execute_reply.started": "2023-07-08T10:06:35.182704Z",
     "shell.execute_reply": "2023-07-08T10:06:35.182726Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-08T10:06:35.184355Z",
     "iopub.status.idle": "2023-07-08T10:06:35.185130Z",
     "shell.execute_reply.started": "2023-07-08T10:06:35.184880Z",
     "shell.execute_reply": "2023-07-08T10:06:35.184903Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
