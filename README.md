Репозиторій для зберігання розв'язків для хакатону <a href="https://csc23.hackathon.expert/">CSC 2023 Hackathon</a>
(LUN.UA task) 

від команди ```Neural Noodles```


-  [Постановка задачі](#постановка-задачі)
- [Структура репозиторію](#стрктура-репозиторію)
-  [Розвідковий аналіз даних](#розвідковий-аналіз-даних)
- [Вибір архітектури та порівняння моделей](#вибір-архітектури-та-порівняння-моделей)
-  [Тренування](#тренування)
- [Підбір порогового значення](#підбір-порового-значення)
- [Витрачений час на prediction](#витрачений-час-на-prediction)
- [Посилання](#посилання)

## Постановка задачі
У цьому змаганні зосередимось на порівнянні near duplicate зображень. 
Це одна і та сама фотографія, яка через розміщення на різних сайтах піддається спотворенням: 
накладанню вотермарків, зміні розміру та пропорцій, додаванню рамок, зміні кольору/контрасту і тд. 
Стаючи іншим зображенням, у сенсі попіксельних порівнянь.
Необхідно побудувати алгоритм попарного порівняння зображень. 
Отримавши на вхід два зображення, він має відповісти «1», якщо вважає їх однаковими і «0», якщо різними.

## Стрктура репозиторію
```
├── delf : реалізація моделі DELF (в розробці)
│  ├── resnet50.py : імплементація ResNet50
│  ├── attention.py : іплементація attention блоку
│  └── delf.py : іплементація класу DELF для поєднання ResNet50 та Attention Block
│
├── eda : директорія для зберігання EDA
│  └── first_eda.ipynb : перший короткий EDA
│
├── notebooks : 
│  ├── siamese : моделі з архітектурою сіамських нейронних мереж
│  │  ├── csc23_vgg16.ipynb : сіамська нейронна мережа з передтренованою VGG-16
│  │  ├── mobilenetv3_simple.ipynb : сіамська нейронна мережа з передтренованою MobileNetV3
│  │  └── triplet_model.ipynb : потрійна сіамська мережа (triplet loss з cosine distance)
│  └── test : ноутбуки для підбору threshold та самбмішину
└──
```

## Розвідковий аналіз даних
Короткий  EDA зберігається в директорії ```eda```. Він збережений у форматі ```.ipynb```. 
З цього кроку ми виділили такі основні моменти:
- початковий датасет незбалансований: кількість семплів дублікатів значно менша. Під час подальшого тренування ми використовували 
новостворений збалансований датасет на ~ 65000 зображень.
- на момент завантаження нами даних близько 1200 зобржаень були видалені.
- зображення мають різний color space (були наявні семпли з grayscale, RGB, RGBA). В подальшому ми все перетворювали в RGB.

## Вибір архітектури та порівняння моделей

### Siamese Network
В першу чергу ми обрали для реалізації архітектуру сіамської нейронної мережі. На вхід подавали пару зображень для порівняння
(нормалізованих в межах [0, 1]), пропускали їх через передтреновану MobileNetV3 на відомому датасеті ImageNet 
(передтренована модель від Google завантажувалась з Tensorflow Hub за <a href="https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5">цим посиланням</a>).
Далі розраховували для отриманих ембедингів cosine_similarity , яку нормалізували в межах від [0, 1], де 
- 1 - кут між векторами наближається до 0, що свідчить про схожість зображень
- 0 - кут між векторами наближається до 180, що свідчить про відмінність

### Triplet Siamese
Після консультації з експертом Володимром Кубицьким ми зрозуміли, що вибір архітектури сіамських нейронних мереж не є оптимальним, 
особливо коли на вхід подається 2 зображення. За однією з його порад, ми видозмінили архітектуру,
тепер на вхід подається 3 зображення - anchor, positive, negative. Вони пропускаються через згадану на попередньому кроці 
MobileNetV3 (потім ми змінили на VGG16), для отриманих ембедингів розраховується triplet loss (код зберігається в директорії ноутбуків ```siamese/triplet_model.ipynb``` )

#### Triplet Loss
Ми трохи змінили розрахунок. В оригінальной формулі рахується L2-норма (евклідова відстань)
між anchor та positive, anchor та negative. Ми ж рахуємо спочатку cosine_similarity, потім

```cosine_distance = 1 - cosine_similarity```

Остаточна функція втрат виглядає так 

```loss = max(pos_cosine_distance + neg_cosine_distance + alpha, 0), alpha = [0,1] ```


### DELF

В розробці

## Тренування

### Siamese Network
Початкову модель тренували на 15 епохах, використовуючи бінарну крос ентропію у якості функції втрат (код зберігається в директорії ноутбуків ```siamese/mobilenetv3_simple.ipynb```). 
Це була одна з перших засабмічених моделей на Kaggle. На 4% даних ми отримали F1 score 0.76. 
Під час тренування зіштовхнулися з перенавченням (в принципі як і на всіх подальших моделях :)). 
Проблему трохи полагодив підбір кращого learning_rate за допомогою grid search.



### Triplet Siamese
Цю модель ми тренували на 10-15 епохах. Зберігали модель у форматі ```.tf```, де потім завантажували 
оновлені ваги для шару, що повертає ембедінги. І власне далі для створення сабмішину (```test/triplet_submission.ipynb```)  
прогоняли пару зображень через цей шар, розраховували ```cosine_similarity``` між ембедінгами та підбирали 
порогове значення ```threshold``` на крос-валідації за допомогою панелі інструментів HParams у Tensorflow.

Вже під час тренування було видно суттєву різницю. На Kaggle ми мали значний приріст у точності - F1 score ~ 0.964.
Після зміни оптимізатора, швидкості навчання для моделі та підбору нового порового значення нам вдалося отримати 0.97712 
на 4% тестових даних. 


### Чому спочатку обрали MobileNetV3 ?
Треба зазначити, що у нашої команди були обмежені часові ресурси та обчислювальні одиниці, тому ми одразу розуміли,
що у якості feature extractor треба обирати модель, що оптимізована для CPU. 

### VGG16
Ми вирішили змінити передтреновану на модель з більш складною архітектурою. І це дало свої результати.
Передтренована VGG16 на ImageNet (тренували лише останні згорткові шари) повертає вектори,
які пропускаємо через 2 лінійних шари з batch нормалізацією.
На Kaggle ми мали приріст у F1 score ~ 0.99397.

### DELF

В розробці

## Підбір порового значення

Підбір порового значення на потрійної сіамської мережі здійснювали 
за допомогою панелі інструментів HParams у Tensorflow. У нас там була не плотна сітка для інтервалу вибору
```threshold``` , найкращим значенням для останньої моделі став ```threshold = 0.75```.

Але з нашого спостереження "краще" порогове 
значення не вирішує проблему, коли негативні (різні) зображення модель вважає дублікатами. 
У початковому датасеті семпли з різними зображеннями були підібрані дуже вдало - вже під час EDA 
було видно зразки, де різні зображення - це фотографії схожих об'єктів, інтер'єрів, схоже освітлення, кольорова гама,
тобто такі hard samples для моделі є кращими, а ми ж по суті рандомізовано обирали третій негативний зразок.

Тому ми вирішили зберегти ваги шару, що повертає ембедінги, з triplet моделі та натренувати нову модель саме на негативних 
зразках, максимізуючи відстань між векторами.

## Витрачений час на prediction


## Посилання
- [1] - <a href="https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5">Передтренована модель MobileNetV3 на ImageNet</a>
- [2] - <a href="https://paperswithcode.com/method/mobilenetv3">Оригінальний пейпер щодо архітектури MobileNetV3</a>
- [3] - <a href="https://github.com/tensorflow/models/tree/master/research/delf"> Реалізація моделі DELF від Tensorflow</a>
- [4] - <a href="https://arxiv.org/pdf/1412.6622.pdf">Deep metric learning using Triplet Network</a>
- [5] - <a href="https://towardsdatascience.com/image-similarity-using-triplet-loss-3744c0f67973">Image similarity using triplet loss</a>
- [6] - <a href="https://keras.io/api/applications/vgg/#vgg16-function">Передтренована модель VGG16 на ImageNet</a>