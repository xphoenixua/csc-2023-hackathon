Репозиторій для зберігання розв'язків для хакатону <a href="https://csc23.hackathon.expert/">CSC 2023 Hackathon</a>
(LUN.UA task) 

від команди ```Neural Noodles```


-  [Постановка задачі](#постановка-задачі)
- [Структура репозиторію](#стрктура-репозиторію)
-  [Розвідковий аналіз даних](#розвідковий-аналіз-даних)
- [Вибір архітектури та порівняння моделей](#вибір-архітектури-та-порівняння-моделей)
-  [Тренування](#data-augmentation)
- [Підбір порогового значення](#training-and-evaluation)
- [Посилання](#references)

## Постановка задачі

## Стрктура репозиторію

## Розвідковий аналіз даних
Короткий  EDA зберігається в директорії ```eda```. Він збережений у форматі ```.ipynb```. 
З цього кроку ми виділили такі основні моменти:
- початковий датасет незбалансований: кількість семплів дублікатів значно менша. Під час подальшого тренування ми використовували 
новостворений збалансований датасет на ~ 65000 зображень.
- на момент завантаження нами даних близько 1200 зобржаень були видалені.
- зображення мають різний color space (були наявні семпли з grayscale, RGB, RGBA). В подальшому ми все перетворювали в RGB.

## Вибір архітектури та порівняння моделей

### Siamese Network
В першу чергу ми обрали для реалізації архітектуру сіамської нейронної мережі. На вхід подавали пару зображень для порівняння
(нормалізованих в межах [0, 1]), пропускали їх через передтреновану MobileNetV3 на відомому датасеті ImageNet 
(передтренована модель від Google завантажувалась з Tensorflow Hub за <a href="https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5">цим посиланням</a>).
Далі розраховували для отриманих ембедингів cosine_similarity , яку нормалізували в межах від [0, 1], де 
- 1 - кут між векторами наближається до 0, що свідчить про схожість зображень
- 0 - кут між векторами наближається до 180, що свідчить про відмінність

### Triplet Siamese
Після консультації з експертом Володимром Кубицьким ми зрозуміли, що вибір архітектури сіамських нейронних мереж не є оптимальним, 
особливо коли на вхід подається 2 зображення. За однією з його порад, ми видозмінили архітектуру,
тепер на вхід подається 3 зображення - anchor, positive, negative. Вони пропускаються через згадану на попередньому кроці 
MobileNetV3, для отриманих ембедингів розраховується triplet loss (код зберігається в директорії ноутбуків ```siamese/triplet_model.ipynb``` )

#### Triplet Loss
Ми трохи змінили розрахунок. В оригінальной формулі рахується L2-норма (евклідова відстань)
між anchor та positive, anchor та negative. Ми ж рахуємо спочатку cosine_similarity, потім

```cosine_distance = 1 - cosine_similarity```

Остаточна функція втрат виглядає так 

```loss = max(pos_cosine_distance + neg_cosine_distance + alpha, 0), alpha = [0,1] ```

### Чому MobileNetV3 ?
Треба зазначити, що у нашої команди були обмежені часові ресурси та обчислювальні одиниці, тому ми одразу розуміли,
що у якості feature extractor треба обирати модель, що оптимізована для CPU.

### DELF

В розробці

## Тренування

### Siamese Network
Початкову модель тренували на 15 епохах, використовуючи бінарну крос ентропію у якості функції втрат (код зберігається в директорії ноутбуків ```siamese/mobilenetv3_simple.ipynb```). 
Це була одна з перших засабмічених моделей на Kaggle. На 4% даних ми отримали F1 score 0.76. 
Під час тренування зіштовхнулися з перенавченням (в принципі як і на всіх подальших моделях :)). 
Проблему трохи полагодив підбір кращого learning_rate за допомогою grid search.



### Triplet Siamese
Цю модель ми тренували на 10-15 епохах. Зберігали модель у форматі ```.tf```, де потім завантажували 
оновлені ваги для шару, що повертає ембедінги. І власне далі для створення сабмішину (```test/triplet_submission.ipynb```)  
прогоняли пару зображень через цей шар, розраховували ```cosine_similarity``` між ембедінгами та підбирали 
порогове значення ```threshold``` на крос-валідації за допомогою grid search.

Вже під час тренування було видно суттєву різницю. На Kaggle ми мали значний приріст у точності - F1 score ~ 0.964.
Після зміни оптимізатора, швидкості навчання для моделі та підбору нового порового значення нам вдалося отримати 0.97712 
на 4% тестових даних. 

### DELF

В розробці

## Підбір порового значення

## Посилання
- [1] - <a href="https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5">Передтренована модель MobileNetV3 на ImageNet</a>
- [2] - <a href="https://paperswithcode.com/method/mobilenetv3">Оригінальний пейпер щодо архітектури MobileNetV3</a>
- [3] - <a href="https://github.com/tensorflow/models/tree/master/research/delf"> Реалізація моделі DELF від Tensorflow</a>
- [4] - <a href="https://arxiv.org/pdf/1412.6622.pdf">Deep metric learning using Triplet Network</a>
- [5] - <a href="https://towardsdatascience.com/image-similarity-using-triplet-loss-3744c0f67973">Image similarity using triplet loss</a>